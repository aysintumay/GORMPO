setting device: cuda:5
Environment without noise
opened the pickle file for synthetic dataset
Model loaded from: /public/gormpo/models/halfcheetah/realnvp_model.pth
Metadata loaded from: /public/gormpo/models/halfcheetah/realnvp_meta_data.pkl
Threshold: -31.227603912353516
training log mean and std of classifier:  5.054104328155518 9.443124771118164
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
[1;32m [info][0m: Start training dynamics
[1;32m [info][0m: loss/model_eval_mse_loss: 18.095221
[1;32m [info][0m: loss/model_eval_mse_loss: 18.071178
[1;32m [info][0m: loss/model_eval_mse_loss: 18.045538
[1;32m [info][0m: loss/model_eval_mse_loss: 18.015654
[1;32m [info][0m: loss/model_eval_mse_loss: 17.978895
[1;32m [info][0m: loss/model_eval_mse_loss: 17.932215
[1;32m [info][0m: loss/model_eval_mse_loss: 17.872211
[1;32m [info][0m: loss/model_eval_mse_loss: 17.795912
[1;32m [info][0m: loss/model_eval_mse_loss: 17.701918
[1;32m [info][0m: loss/model_eval_mse_loss: 17.593327
[1;32m [info][0m: loss/model_eval_mse_loss: 17.479704
[1;32m [info][0m: loss/model_eval_mse_loss: 17.376419
[1;32m [info][0m: loss/model_eval_mse_loss: 17.297199
[1;32m [info][0m: loss/model_eval_mse_loss: 17.270611
[1;32m [info][0m: loss/model_eval_mse_loss: 17.241268
[1;32m [info][0m: loss/model_eval_mse_loss: 17.192284
[1;32m [info][0m: loss/model_eval_mse_loss: 17.115747
[1;32m [info][0m: loss/model_eval_mse_loss: 17.014185
[1;32m [info][0m: loss/model_eval_mse_loss: 16.894260
[1;32m [info][0m: loss/model_eval_mse_loss: 16.754452
[1;32m [info][0m: loss/model_eval_mse_loss: 16.595779
[1;32m [info][0m: loss/model_eval_mse_loss: 16.427549
[1;32m [info][0m: loss/model_eval_mse_loss: 16.259531
[1;32m [info][0m: loss/model_eval_mse_loss: 16.098049
[1;32m [info][0m: loss/model_eval_mse_loss: 15.946678
[1;32m [info][0m: loss/model_eval_mse_loss: 15.811612
[1;32m [info][0m: loss/model_eval_mse_loss: 15.698222
[1;32m [info][0m: loss/model_eval_mse_loss: 15.604935
[1;32m [info][0m: loss/model_eval_mse_loss: 15.532254
[1;32m [info][0m: loss/model_eval_mse_loss: 15.479897
[1;32m [info][0m: loss/model_eval_mse_loss: 15.447023
[1;32m [info][0m: loss/model_eval_mse_loss: 15.432825
[1;32m [info][0m: loss/model_eval_mse_loss: 15.445620
[1;32m [info][0m: loss/model_eval_mse_loss: 15.461263
[1;32m [info][0m: loss/model_eval_mse_loss: 15.481795
[1;32m [info][0m: loss/model_eval_mse_loss: 15.491637
[1;32m [info][0m: loss/model_eval_mse_loss: 15.504907
[1;32m [info][0m: loss/model_eval_mse_loss: 15.512329
[1;32m [info][0m: loss/model_eval_mse_loss: 15.506200
[1;32m [info][0m: loss/model_eval_mse_loss: 15.487556
[1;32m [info][0m: loss/model_eval_mse_loss: 15.456484
[1;32m [info][0m: loss/model_eval_mse_loss: 15.413058
[1;32m [info][0m: loss/model_eval_mse_loss: 15.371704
[1;32m [info][0m: loss/model_eval_mse_loss: 15.296279
[1;32m [info][0m: loss/model_eval_mse_loss: 15.215856
[1;32m [info][0m: loss/model_eval_mse_loss: 15.130220
[1;32m [info][0m: loss/model_eval_mse_loss: 15.035294
[1;32m [info][0m: loss/model_eval_mse_loss: 14.946197
[1;32m [info][0m: loss/model_eval_mse_loss: 14.866236
[1;32m [info][0m: loss/model_eval_mse_loss: 14.792335
[1;32m [info][0m: loss/model_eval_mse_loss: 14.725123
[1;32m [info][0m: loss/model_eval_mse_loss: 14.669646
[1;32m [info][0m: loss/model_eval_mse_loss: 14.629112
[1;32m [info][0m: loss/model_eval_mse_loss: 14.606043
[1;32m [info][0m: loss/model_eval_mse_loss: 14.600621
[1;32m [info][0m: loss/model_eval_mse_loss: 14.613702
[1;32m [info][0m: loss/model_eval_mse_loss: 14.629662
[1;32m [info][0m: loss/model_eval_mse_loss: 14.662169
[1;32m [info][0m: loss/model_eval_mse_loss: 14.719441
[1;32m [info][0m: loss/model_eval_mse_loss: 14.779773
[1;32m [info][0m: total time: 1.226s
Epoch #1/1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 665/1000 [00:08<00:04, 78.71it/s, alpha=0.819, entropy=4.1, loss/actor=-3.57, loss/alpha=-2.02, loss/critic1=32.2, loss/critic2=2.12]
Traceback (most recent call last):
  File "mopo.py", line 181, in <module>
    main(args=get_args())
  File "mopo.py", line 161, in main
    policy, trainer = train(env, run, logger, seed, args)
  File "/home/ubuntu/GORMPO/train.py", line 189, in train
    trainer.train_policy()
  File "/home/ubuntu/GORMPO/trainer.py", line 118, in train_policy
    loss,q_values = self.algo.learn_policy()
  File "/home/ubuntu/GORMPO/algo/mopo.py", line 164, in learn_policy
    loss,q_values = self.policy.learn(data)
  File "/home/ubuntu/GORMPO/algo/sac.py", line 100, in learn
    self.critic1_old(next_obs, next_actions), self.critic2_old(next_obs, next_actions)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/GORMPO/models/policy_models.py", line 55, in forward
    values = self.last(logits)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
Traceback (most recent call last):
  File "mopo.py", line 181, in <module>
    main(args=get_args())
  File "mopo.py", line 161, in main
    policy, trainer = train(env, run, logger, seed, args)
  File "/home/ubuntu/GORMPO/train.py", line 189, in train
    trainer.train_policy()
  File "/home/ubuntu/GORMPO/trainer.py", line 118, in train_policy
    loss,q_values = self.algo.learn_policy()
  File "/home/ubuntu/GORMPO/algo/mopo.py", line 164, in learn_policy
    loss,q_values = self.policy.learn(data)
  File "/home/ubuntu/GORMPO/algo/sac.py", line 100, in learn
    self.critic1_old(next_obs, next_actions), self.critic2_old(next_obs, next_actions)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/GORMPO/models/policy_models.py", line 55, in forward
    values = self.last(logits)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/gormpo/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
